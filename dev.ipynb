{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa450fc-71fa-44b0-8630-daaddb3d5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "# from edison_client import EdisonClient, JobNames\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# trajectory_id = \"2e8d7bbb-8cb9-4b7d-b94a-2e34c8254c59\"\n",
    "# api_key = os.environ.get(\"EDISON_API_KEY\")\n",
    "\n",
    "# client = EdisonClient(api_key=api_key)\n",
    "# task_response = client.get_task(trajectory_id)\n",
    "# task_response\n",
    "projects_dir = Path(\"projects\")\n",
    "project_name = \"cpas\"\n",
    "projects_dir.mkdir(exist_ok=True, parents=True)\n",
    "project_dir = projects_dir / project_name\n",
    "project_dir.mkdir(exist_ok=True, parents=True)\n",
    "# with open(project_dir / f\"task_response_{trajectory_id}.json\", \"w\") as f:\n",
    "#     f.write(task_response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from papers2dataset.bfs_queue import BFSQueue\n",
    "from papers2dataset.openalex_client import fetch_work\n",
    "\n",
    "q = BFSQueue(project_dir / \"bfs_queue.json\")\n",
    "# search_result = search_works(\"High-Throughput Evaluation of Cryoprotective Agents for\")\n",
    "# q.add_many([x.get(\"id\", \"\").split('/')[-1] for x in search_result['results']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fcfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from papers2dataset.openalex_client import fetch_pdf\n",
    "from papers2dataset.openalex_client import (\n",
    "    fetch_cited_works,\n",
    "    fetch_citing_works,\n",
    "    fetch_related_works,\n",
    ")\n",
    "from papers2dataset.extractor import extract_cpa_from_pdf\n",
    "from papers2dataset.extractor import check_paper_relevance\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    pid = q.pop()\n",
    "    paper = fetch_work(pid)\n",
    "    pdf_path = fetch_pdf(paper, project_dir)\n",
    "    if pdf_path is None:\n",
    "        print(f\"Failed to download PDF for {paper['id']}\")\n",
    "        q.mark_failed(pid, \"no_pdf\")\n",
    "        continue\n",
    "\n",
    "    res = check_paper_relevance(paper)\n",
    "    if not res['has_cpa_compositions']:\n",
    "        print(f\"Paper {paper['id']} is not relevant because {res['reason']}\")\n",
    "        q.mark_skipped(pid, res['reason'])\n",
    "        continue\n",
    "\n",
    "    resp = extract_cpa_from_pdf(pdf_path, project_dir)\n",
    "\n",
    "\n",
    "    related_works = fetch_related_works(pid)\n",
    "    cited_works = fetch_cited_works(pid)\n",
    "    citing_works = fetch_citing_works(pid)\n",
    "\n",
    "\n",
    "    q.add_many([x.get(\"id\", \"\").split('/')[-1] for x in related_works+cited_works+citing_works])\n",
    "    q.mark_processed(pid)\n",
    "    print(f\"Processed {paper['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "from papers2dataset.openalex_client import fetch_work, fetch_pdf, fetch_cited_works, fetch_citing_works, fetch_related_works\n",
    "from papers2dataset.extractor import extract_cpa_from_pdf, check_paper_relevance\n",
    "\n",
    "# Configuration\n",
    "MAX_CONCURRENT = 5  # Number of papers to process in parallel\n",
    "\n",
    "async def process_one_paper(pid, q, project_dir, semaphore):\n",
    "    \"\"\"Processes a single paper ID through the pipeline.\"\"\"\n",
    "    async with semaphore:\n",
    "        # paper = fetch_work(pid)\n",
    "        paper = await asyncio.to_thread(fetch_work, pid)\n",
    "        if not paper:\n",
    "            print(f\"Failed to fetch metadata for {pid}\")\n",
    "            q.mark_failed(pid, \"metadata_fetch_failed\")\n",
    "            return\n",
    "\n",
    "        # pdf_path = fetch_pdf(paper, project_dir)\n",
    "        pdf_path = await asyncio.to_thread(fetch_pdf, paper, project_dir)\n",
    "        if pdf_path is None:\n",
    "            print(f\"Failed to download PDF for {paper['id']}\")\n",
    "            q.mark_failed(pid, \"no_pdf\")\n",
    "            return\n",
    "\n",
    "        # res = check_paper_relevance(paper)\n",
    "        res = await asyncio.to_thread(check_paper_relevance, paper)\n",
    "        if not res['has_cpa_compositions']:\n",
    "            print(f\"Paper {paper.get('id')} is not relevant because {res.get('reason')}\")\n",
    "            q.mark_skipped(pid, res.get('reason'))\n",
    "            return\n",
    "\n",
    "        # THE SLOW LLM CALL\n",
    "        resp = await asyncio.to_thread(extract_cpa_from_pdf, pdf_path, project_dir)\n",
    "        if resp.get(\"error\"):\n",
    "            print(f\"Failed to extract CPA from PDF for {paper['id']}\")\n",
    "            q.mark_failed(pid, resp['error'])\n",
    "            return\n",
    "\n",
    "        # Parallelize fetching graph connections for this paper\n",
    "        related_task = asyncio.to_thread(fetch_related_works, pid)\n",
    "        cited_task = asyncio.to_thread(fetch_cited_works, pid)\n",
    "        citing_task = asyncio.to_thread(fetch_citing_works, pid)\n",
    "        \n",
    "        related, cited, citing = await asyncio.gather(related_task, cited_task, citing_task)\n",
    "\n",
    "        # Update the queue (now thread-safe)\n",
    "        new_ids = [x.get(\"id\", \"\").split('/')[-1] for x in related + cited + citing]\n",
    "        q.add_many(new_ids)\n",
    "        q.mark_processed(pid)\n",
    "        print(f\"âœ… Processed {paper['id']}\")\n",
    "            \n",
    "\n",
    "async def run_async_pipeline(q, project_dir, num_items=30):\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n",
    "    tasks = []\n",
    "    \n",
    "    # 1. Pop IDs from the queue first\n",
    "    for _ in range(num_items):\n",
    "        pid = q.pop()\n",
    "        if not pid:\n",
    "            break\n",
    "        tasks.append(process_one_paper(pid, q, project_dir, semaphore))\n",
    "    \n",
    "    if not tasks:\n",
    "        print(\"Queue is empty.\")\n",
    "        return\n",
    "\n",
    "    # 2. Run all tasks with a progress bar\n",
    "    await tqdm.gather(*tasks)\n",
    "\n",
    "# Usage in Jupyter (top-level await)\n",
    "await run_async_pipeline(q, project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1eeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
